<!--
  ~ Copyright (c) 2014 Wipro Limited
  ~ All Rights Reserved
  ~
  ~ This code is protected by copyright and distributed under
  ~ licenses restricting copying, distribution and decompilation.
  -->

<!-- Note never have '.' in the xml tag names/ e.g instead of <my.tag> use <my-tag>-->
<config>
    <environments>
        <default id="development"/>
        <environment id="env1">
            <common>
                <default-fs-name>hdfs://192.168.56.101:8020</default-fs-name>
            </common>
            <etl>
                <hive-connection>jdbc:hive2://192.168.56.101:10000/</hive-connection>
                <hdfs-raw-directory>/stg</hdfs-raw-directory>
                <hive-metastore-uris>thrift://192.168.56.101:9083</hive-metastore-uris>
                <local-download-directory>/Users/arijit/Downloads</local-download-directory>
            </etl>
            <file-mon>
                <thread-wait>1000</thread-wait>
                <dirs>/tmp/arijit,/tmp/arijit</dirs>
                <filter>xaa[0-9].csv,xab[0-9].csv</filter>
                <sub-processIds>540,542</sub-processIds>
                <serverIds>1,1</serverIds>
            </file-mon>
            <eventing>
                <metadata-broker-list>192.168.56.101:9092</metadata-broker-list>
            </eventing>
            <dq>
                <drools-url-prefix>http://54.173.62.30:8585/guvnor56/rest/packages/</drools-url-prefix>
            </dq>
            <data-import>
                <hadoop-home>/usr/lib/hadoop</hadoop-home>
                <target-dir>hdfs://localhost/user/cloudera/import</target-dir>
                <jar-output-dir>/home/cloudera/outputdir/jar-output</jar-output-dir>
            </data-import>
            <mq-import>
                <file-size-units>KB</file-size-units>
                <rotation-file-size>5</rotation-file-size>
                <target-directory>hdfs://localhost/user/cloudera/mq-import</target-directory>
            </mq-import>
        </environment>
        <environment id="development">
            <common>
                <default-fs-name>hdfs://10.0.0.214:8020</default-fs-name>
            </common>
            <etl>
                <hive-connection>jdbc:hive2://10.0.0.214:10000/</hive-connection>
                <hdfs-raw-directory>/raw</hdfs-raw-directory>
                <hive-metastore-uris>thrift://10.0.0.214:9083</hive-metastore-uris>
                <local-download-directory>/home/dropuser/Downloads</local-download-directory>
            </etl>
            <file-mon>
                <thread-wait>500</thread-wait>
                <dirs>/home/cloudera/oozies,/home/cloudera/datasets</dirs>
                <filter>merchant\s[0-9],test\s[0-9]</filter>
                <sub-processIds>1,2</sub-processIds>
                <serverIds>100,200</serverIds>
            </file-mon>
            <dq>
                <drools-url-prefix>http://54.173.62.30:8585/guvnor56/rest/packages/</drools-url-prefix>
            </dq>
            <data-import>
                <hadoop-home>/opt/cloudera/parcels/CDH-5.3.2-1.cdh5.3.2.p0.10/lib/hadoop</hadoop-home>
                <target-dir>hdfs://ip-10-0-0-214.ec2.internal:8020/user/dropuser/import</target-dir>
                <jar-output-dir>/tmp</jar-output-dir>
            </data-import>
            <mq-import>
                <file-size-units>KB</file-size-units>
                <rotation-file-size>10</rotation-file-size>
                <target-directory>hdfs://ip-10-0-0-214.ec2.internal:8020/user/dropuser/mq-import</target-directory>
            </mq-import>
        </environment>

        <environment id="jayabroto">
            <common>
                <default-fs-name>hdfs://10.0.0.214:8020</default-fs-name>
            </common>
            <etl>
                <!-- <hive-connection>jdbc:hive2://10.0.0.214:10000/</hive-connection> -->
                <hive-connection>jdbc:hive2://127.0.0.1:10000/</hive-connection>
                <hdfs-raw-directory>/raw</hdfs-raw-directory>
                <hive-metastore-uris>thrift://10.0.0.214:9083</hive-metastore-uris>
                <local-download-directory>/home/dropuser/Downloads</local-download-directory>
            </etl>
            <file-mon>
                <thread-wait>500</thread-wait>
                <dirs>/home/cloudera/oozies,/home/cloudera/datasets</dirs>
                <filter>merchant\s[0-9],test\s[0-9]</filter>
                <sub-processIds>1,2</sub-processIds>
                <serverIds>100,200</serverIds>
            </file-mon>
            <dq>
                <drools-url-prefix>http://54.173.62.30:8585/guvnor56/rest/packages/</drools-url-prefix>
            </dq>
			<data-import>
                <hadoop-home>/usr/lib/hadoop</hadoop-home>
                <target-dir>hdfs://localhost/user/cloudera/import</target-dir>
                <jar-output-dir>/home/cloudera/outputdir/jar-output</jar-output-dir>
            </data-import>
            <mq-import>
                <file-size-units>KB</file-size-units>
                <rotation-file-size>10</rotation-file-size>
                <target-directory>hdfs://localhost/user/cloudera/mq-import</target-directory>
            </mq-import>
        </environment>

        <environment id="env2">
            <common>
                <default-fs-name>hdfs://quickstart.cloudera:8020</default-fs-name>
            </common>
            <etl>
                <hive-connection>jdbc:hive2://quickstart.cloudera:10000/</hive-connection>
                <hdfs-raw-directory>/stg</hdfs-raw-directory>
                <hive-metastore-uris>thrift://quickstart.cloudera:9083</hive-metastore-uris>
                <local-download-directory>/home/cloudera/dataset</local-download-directory>
            </etl>
            <file-mon>
                <thread-wait>500</thread-wait>
                <dirs>/home/cloudera/oozies,/home/cloudera/datasets</dirs>
                <filter>merchant\s[0-9],test\s[0-9]</filter>
                <sub-processIds>213,214</sub-processIds>
                <serverIds>1,1</serverIds>
            </file-mon>
            <dq>
                <drools-url-prefix>http://54.173.62.30:8585/guvnor56/rest/packages/</drools-url-prefix>
            </dq>
            <data-import>
                <hadoop-home>/usr/lib/hadoop</hadoop-home>
                <target-dir>hdfs://localhost/user/cloudera/import</target-dir>
                <jar-output-dir>/home/cloudera/outputdir/jar-output</jar-output-dir>
            </data-import>
            <mq-import>
                <file-size-units>KB</file-size-units>
                <rotation-file-size>10</rotation-file-size>
                <target-directory>hdfs://localhost/user/cloudera/mq-import</target-directory>
            </mq-import>
        </environment>

        <environment id="ishita">
            <common>
                <default-fs-name>hdfs://192.168.186.2:8020</default-fs-name>
            </common>
            <etl>
                <hive-connection>jdbc:hive2://192.168.186.2:10000/</hive-connection>
                <hdfs-raw-directory>/raw</hdfs-raw-directory>
                <hive-metastore-uris>thrift://192.168.186.2:9083</hive-metastore-uris>
                <local-download-directory>/Users/arijit/Downloads</local-download-directory>
            </etl>
            <file-mon>
                <thread-wait>500</thread-wait>
                <dirs>/home/cloudera/oozies,/home/cloudera/datasets</dirs>
                <filter>merchant\s[0-9],test\s[0-9]</filter>
                <sub-processIds>1,2</sub-processIds>
                <serverIds>100,200</serverIds>
            </file-mon>
            <eventing>
                <metadata-broker-list>192.168.56.101:9092</metadata-broker-list>
            </eventing>
            <dq>
                <drools-url-prefix>http://54.173.62.30:8585/guvnor56/rest/packages/</drools-url-prefix>
            </dq>
            <data-import>
                <hadoop-home>/usr/lib/hadoop</hadoop-home>
                <target-dir>hdfs://localhost/user/cloudera/import</target-dir>
                <jar-output-dir>/home/cloudera/outputdir/jar-output</jar-output-dir>
            </data-import>
            <mq-import>
                <file-size-units>KB</file-size-units>
                <rotation-file-size>10</rotation-file-size>
                <target-directory>hdfs://localhost/user/cloudera/mq-import</target-directory>
            </mq-import>
        </environment>
        <environment id="mishi">
            <common>
                <default-fs-name>hdfs://192.168.56.101:8020</default-fs-name>
            </common>
            <etl>
                <hive-connection>jdbc:hive2://192.168.56.101:10000/</hive-connection>
                <hdfs-raw-directory>/raw</hdfs-raw-directory>
                <hive-metastore-uris>thrift://192.168.186.2:9083</hive-metastore-uris>
                <local-download-directory>/Users/arijit/Downloads</local-download-directory>
            </etl>
            <file-mon>
                <thread-wait>500</thread-wait>
                <dirs>/home/cloudera/oozies,/home/cloudera/datasets</dirs>
                <filter>merchant\s[0-9],test\s[0-9]</filter>
                <sub-processIds>1,2</sub-processIds>
                <serverIds>100,200</serverIds>
            </file-mon>
            <eventing>
                <metadata-broker-list>192.168.56.101:9092</metadata-broker-list>
            </eventing>
            <dq>
                <drools-url-prefix>http://54.173.62.30:8585/guvnor56/rest/packages/</drools-url-prefix>
            </dq>
            <data-import>
                <hadoop-home>/usr/lib/hadoop</hadoop-home>
                <target-dir>hdfs://localhost/user/cloudera/import</target-dir>
                <jar-output-dir>/home/cloudera/outputdir/jar-output</jar-output-dir>
            </data-import>
            <mq-import>
                <file-size-units>KB</file-size-units>
                <rotation-file-size>10</rotation-file-size>
                <target-directory>hdfs://localhost/user/cloudera/mq-import</target-directory>
            </mq-import>
        </environment>
        <environment id="vm">
            <common>
                <default-fs-name>hdfs://192.168.56.102:8020</default-fs-name>
            </common>
            <etl>
                <hive-connection>jdbc:hive2://192.168.56.102:10000/</hive-connection>
                <hdfs-raw-directory>/raw</hdfs-raw-directory>
                <hive-metastore-uris>thrift://192.168.186.2:9083</hive-metastore-uris>
                <local-download-directory>/Users/arijit/Downloads</local-download-directory>
            </etl>
            <file-mon>
                <thread-wait>500</thread-wait>
                <dirs>/home/cloudera/oozies,/home/cloudera/datasets</dirs>
                <filter>merchant\s[0-9],test\s[0-9]</filter>
                <sub-processIds>1,2</sub-processIds>
                <serverIds>100,200</serverIds>
            </file-mon>
            <eventing>
                <metadata-broker-list>192.168.56.101:9092</metadata-broker-list>
            </eventing>
            <dq>
                <drools-url-prefix>http://54.173.62.30:8585/guvnor56/rest/packages/</drools-url-prefix>
            </dq>
            <data-import>
                <hadoop-home>/usr/lib/hadoop</hadoop-home>
                <target-dir>hdfs://localhost/user/cloudera/import</target-dir>
                <jar-output-dir>/home/cloudera/outputdir/jar-output</jar-output-dir>
            </data-import>
            <mq-import>
                <file-size-units>KB</file-size-units>
                <rotation-file-size>10</rotation-file-size>
                <target-directory>hdfs://192.168.56.102:8020/user/cloudera/mq-import</target-directory>
            </mq-import>
        </environment>
        <environment id="vidya">
            <common>
                <default-fs-name>hdfs://192.168.56.101:8020</default-fs-name>
            </common>
            <etl>
                <hive-connection>jdbc:hive2://192.168.56.101:10000/</hive-connection>
                <hdfs-raw-directory>/raw</hdfs-raw-directory>
                <hive-metastore-uris>thrift://192.168.186.2:9083</hive-metastore-uris>
                <local-download-directory>/Users/arijit/Downloads</local-download-directory>
            </etl>
            <file-mon>
                <thread-wait>500</thread-wait>
                <dirs>/home/cloudera/oozies,/home/cloudera/datasets</dirs>
                <filter>merchant\s[0-9],test\s[0-9]</filter>
                <sub-processIds>1,2</sub-processIds>
                <serverIds>100,200</serverIds>
            </file-mon>
            <eventing>
                <metadata-broker-list>192.168.56.101:9092</metadata-broker-list>
            </eventing>
            <dq>
                <drools-url-prefix>http://54.173.62.30:8585/guvnor56/rest/packages/</drools-url-prefix>
            </dq>
            <data-import>
                <hadoop-home>/usr/lib/hadoop</hadoop-home>
                <target-dir>hdfs://localhost/user/cloudera/import</target-dir>
                <jar-output-dir>/home/cloudera/outputdir/jar-output</jar-output-dir>
            </data-import>
            <data-export>
                <hadoop-home>/usr/lib/hadoop</hadoop-home>
                <jar-output-dir>/home/cloudera/outputdir/jar-output</jar-output-dir>
            </data-export>
            <mq-import>
                <file-size-units>KB</file-size-units>
                <rotation-file-size>10</rotation-file-size>
                <target-directory>hdfs://localhost/user/cloudera/mq-import</target-directory>
            </mq-import>
        </environment>
        <environment id="neutron">
            <common>
                <default-fs-name>hdfs://localhost:8020</default-fs-name>
            </common>
            <etl>
                <hive-connection>jdbc:hive2://localhost:10000/</hive-connection>
                <hdfs-raw-directory>/raw</hdfs-raw-directory>
                <hive-metastore-uris>thrift://localhost:9083</hive-metastore-uris>
                <local-download-directory>/home/dropuser/Downloads</local-download-directory>
            </etl>
            <file-mon>
                <thread-wait>500</thread-wait>
                <dirs>/home/cloudera/oozies,/home/cloudera/datasets</dirs>
                <filter>merchant\s[0-9],test\s[0-9]</filter>
                <sub-processIds>1,2</sub-processIds>
                <serverIds>100,200</serverIds>
            </file-mon>
            <dq>
                <drools-url-prefix>http://localhost:8080/guvnor56/rest/packages/</drools-url-prefix>
            </dq>
            <data-import>
                <hadoop-home>/usr/lib/hadoop</hadoop-home>
                <target-dir>hdfs://localhost:8020/user/dropuser/import</target-dir>
                <jar-output-dir>/tmp</jar-output-dir>
            </data-import>
            <mq-import>
                <file-size-units>KB</file-size-units>
                <rotation-file-size>10</rotation-file-size>
                <target-directory>hdfs://localhost:8020/user/dropuser/mq-import</target-directory>
            </mq-import>
        </environment>

		<environment id="aws-hdp">
            <common>
                <default-fs-name>hdfs://aws-hdp-internal-ip:8020</default-fs-name>
            </common>
            <etl>
                <hive-connection>jdbc:hive2://aws-hdp-internal-ip:10000/</hive-connection>
                <hdfs-raw-directory>/raw</hdfs-raw-directory>
                <hive-metastore-uris>thrift://aws-hdp-internal-ip:9083</hive-metastore-uris>
                <local-download-directory>/home/bdreusr/Downloads</local-download-directory>
            </etl>
            <file-mon>
                <thread-wait>500</thread-wait>
                <dirs>/home/bdreusr/oozies,/home/bdreusr/datasets</dirs>
                <filter>merchant\s[0-9],test\s[0-9]</filter>
                <sub-processIds>1,2</sub-processIds>
                <serverIds>100,200</serverIds>
            </file-mon>
            <dq>
                <drools-url-prefix>http://aws-hdp-internal-ip:8080/guvnor56/rest/packages/</drools-url-prefix>
            </dq>
            <data-import>
                <hadoop-home>/usr/lib/hadoop</hadoop-home>
                <target-dir>hdfs://aws-hdp-internal-ip:8020/user/dropuser/import</target-dir>
                <jar-output-dir>/tmp</jar-output-dir>
            </data-import>
            <mq-import>
                <file-size-units>KB</file-size-units>
                <rotation-file-size>10</rotation-file-size>
                <target-directory>hdfs://aws-hdp-internal-ip:8020/user/dropuser/mq-import</target-directory>
            </mq-import>
        </environment>
		
    </environments>
</config>
